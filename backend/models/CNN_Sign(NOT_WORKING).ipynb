{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "40h4b7OFEeve"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pic_size = 48\n",
        "batch_size = 128\n",
        "base_path = \"/content/content/opencv4/1\"\n",
        "\n",
        "# Aumento de datos para el conjunto de entrenamiento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(base_path),\n",
        "    target_size=(pic_size, pic_size),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    os.path.join(base_path),\n",
        "    target_size=(pic_size, pic_size),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "import os\n",
        "print(os.listdir(base_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDETMVwyEi29",
        "outputId": "e5fc3cc4-7228-4218-f177-08c02e00b0e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n",
            "['Q.jpg', 'D.jpg', 'T.jpg', 'F.jpg', 'J.jpg', 'G.jpg', 'O.jpg', 'R.jpg', 'Y.jpg', 'Z.jpg', 'I.jpg', 'V.jpg', 'K.jpg', 'X.jpg', 'N.jpg', 'A.jpg', 'L.jpg', 'H.jpg', 'B.jpg', 'C.jpg', 'E.jpg', 'U.jpg', 'P.jpg', 'W.jpg', '.ipynb_checkpoints', 'M.jpg', 'S.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 26\n",
        "\n",
        "# Inicializando la CNN\n",
        "model = Sequential()\n",
        "\n",
        "# | 1. Capa de Convolución\n",
        "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 2. Capa de Convolución\n",
        "model.add(Conv2D(128,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 3. Capa de Convolución\n",
        "model.add(Conv2D(256,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 4. Capa de Convolución\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# | 1. Capa Totalmente Conectada\n",
        "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 2. Capa Totalmente Conectada\n",
        "model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 3. Capa Totalmente Conectada\n",
        "model.add(Dense(512, kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 4. Capa Totalmente Conectada\n",
        "model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# | 5. Capa Totalmente Conectada\n",
        "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "# Inicialización del optimizador RMSprop\n",
        "opt = RMSprop(lr=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mVxIkCFTEkoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(\"model_4_weights.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, early_stopping, reduce_lr]\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.n//validation_generator.batch_size,\n",
        "    callbacks=callbacks_list)\n",
        "\n",
        "# Guardar el modelo y la arquitectura\n",
        "model.save(\"model_4.h5\")\n",
        "\n",
        "json_config = model.to_json()\n",
        "with open('arch_model_4.json', 'w') as json_file:\n",
        "    json_file.write(json_config)"
      ],
      "metadata": {
        "id": "6tIMxv_CEyGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sfBeBIs8EysL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo\n",
        "model_4 = load_model(\"model_4.h5\")\n",
        "\n",
        "# Cargar y preprocesar la imagen\n",
        "img = load_img('/content/disgust.jpg', target_size=(48, 48), color_mode=\"grayscale\")\n",
        "img = img_to_array(img)\n",
        "img = img / 255.0\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "emotion_dict = {0: 'Felicidad', 1: 'Tristeza', 2: 'Sorpresa', 3: 'Enojo', 4: 'Disgusto', 5: 'Miedo', 6: 'Neutral'}\n",
        "\n",
        "# Hacer la predicción\n",
        "predictions = model_4.predict(img)\n",
        "\n",
        "# Obtener la clase con la mayor probabilidad\n",
        "class_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Obtener el nombre de la emoción\n",
        "predicted_emotion = emotion_dict[class_index[0]]\n",
        "\n",
        "print(\"La emoción predicha es:\", predicted_emotion)"
      ],
      "metadata": {
        "id": "ThvVoAgDE3Hx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}