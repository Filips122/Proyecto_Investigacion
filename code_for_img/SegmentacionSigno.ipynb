{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "original_img_path = \"/content/1.jpg\"\n",
        "original_img = cv2.imread(original_img_path)\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Threshold to get just the sign\n",
        "_, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(threshed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Function to get the bounding rectangle for a list of points\n",
        "def get_bounding_box(points):\n",
        "    x_coordinates, y_coordinates = zip(*points)\n",
        "    return (min(x_coordinates), min(y_coordinates), max(x_coordinates), max(y_coordinates))\n",
        "\n",
        "# Calculate bounding boxes for each contour\n",
        "bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
        "\n",
        "# Only take the largest 26 bounding boxes (assuming these are the signs)\n",
        "largest_bounding_boxes = sorted(bounding_boxes, key=lambda x: x[2]*x[3], reverse=True)[:26]\n",
        "\n",
        "# Function to sort bounding boxes by rows and then by x within each row\n",
        "def sort_by_rows(bounding_boxes, nx, ny):\n",
        "    # Calculate the average height of all bounding boxes to estimate the height of a row\n",
        "    avg_height = np.mean([box[3] for box in bounding_boxes])\n",
        "\n",
        "    # Group boxes by rows based on vertical position\n",
        "    rows = [[] for _ in range(ny)]\n",
        "    for box in bounding_boxes:\n",
        "        row_index = min(int(box[1] // avg_height), ny - 1)  # Assign box to a row based on its vertical position\n",
        "        rows[row_index].append(box)\n",
        "\n",
        "    # Sort boxes within each row based on horizontal position\n",
        "    sorted_rows = [sorted(row, key=lambda box: box[0]) for row in rows]\n",
        "\n",
        "    # Flatten sorted rows into a single list of boxes\n",
        "    sorted_boxes = [box for row in sorted_rows for box in row]\n",
        "\n",
        "    return sorted_boxes\n",
        "\n",
        "# Apply the sorting by rows\n",
        "sorted_boxes_by_rows = sort_by_rows(largest_bounding_boxes, 6, 5)\n",
        "\n",
        "# Crop images based on the sorted boxes\n",
        "grid_cropped_signs = [original_img[y:y+h, x:x+w] for x, y, w, h in sorted_boxes_by_rows]\n",
        "\n",
        "# Save the cropped images\n",
        "grid_file_paths = []\n",
        "for index, img in enumerate(grid_cropped_signs):\n",
        "    file_path = f\"/content/opencv2/1/sign_{chr(65 + index)}.jpg\"\n",
        "    cv2.imwrite(file_path, img)\n",
        "    grid_file_paths.append(file_path)\n",
        "\n",
        "grid_file_paths\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1s6F5QKsVze",
        "outputId": "508bbb75-069b-4b91-832c-592f3c7483a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/opencv2/1/sign_A.jpg',\n",
              " '/content/opencv2/1/sign_B.jpg',\n",
              " '/content/opencv2/1/sign_C.jpg',\n",
              " '/content/opencv2/1/sign_D.jpg',\n",
              " '/content/opencv2/1/sign_E.jpg',\n",
              " '/content/opencv2/1/sign_F.jpg',\n",
              " '/content/opencv2/1/sign_G.jpg',\n",
              " '/content/opencv2/1/sign_H.jpg',\n",
              " '/content/opencv2/1/sign_I.jpg',\n",
              " '/content/opencv2/1/sign_J.jpg',\n",
              " '/content/opencv2/1/sign_K.jpg',\n",
              " '/content/opencv2/1/sign_L.jpg',\n",
              " '/content/opencv2/1/sign_M.jpg',\n",
              " '/content/opencv2/1/sign_N.jpg',\n",
              " '/content/opencv2/1/sign_O.jpg',\n",
              " '/content/opencv2/1/sign_P.jpg',\n",
              " '/content/opencv2/1/sign_Q.jpg',\n",
              " '/content/opencv2/1/sign_R.jpg',\n",
              " '/content/opencv2/1/sign_S.jpg',\n",
              " '/content/opencv2/1/sign_T.jpg',\n",
              " '/content/opencv2/1/sign_U.jpg',\n",
              " '/content/opencv2/1/sign_V.jpg',\n",
              " '/content/opencv2/1/sign_W.jpg',\n",
              " '/content/opencv2/1/sign_X.jpg',\n",
              " '/content/opencv2/1/sign_Y.jpg',\n",
              " '/content/opencv2/1/sign_Z.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "original_img_path = \"/content/4.jpg\"\n",
        "original_img = cv2.imread(original_img_path)\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Umbralización Adaptativa\n",
        "thresh_adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                        cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(thresh_adaptive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Function to get the bounding rectangle for a list of points\n",
        "def get_bounding_box(points):\n",
        "    x_coordinates, y_coordinates = zip(*points)\n",
        "    return (min(x_coordinates), min(y_coordinates), max(x_coordinates), max(y_coordinates))\n",
        "\n",
        "# Calculate bounding boxes for each contour\n",
        "bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
        "\n",
        "# Only take the largest 26 bounding boxes (assuming these are the signs)\n",
        "largest_bounding_boxes = sorted(bounding_boxes, key=lambda x: x[2]*x[3], reverse=True)[:26]\n",
        "\n",
        "# Función actualizada para ordenar cuadros delimitadores en 4 filas dinámicamente\n",
        "def sort_by_rows_dynamic(bounding_boxes, num_rows):\n",
        "    # Calcular la altura total de la imagen para estimar la altura de una fila\n",
        "    total_height = max([y + h for _, y, _, h in bounding_boxes]) - min([y for _, y, _, _ in bounding_boxes])\n",
        "    row_height = total_height / num_rows\n",
        "\n",
        "    # Agrupar cuadros por filas basándose en la posición vertical\n",
        "    rows = [[] for _ in range(num_rows)]\n",
        "    for box in bounding_boxes:\n",
        "      row_index = int(box[1] // row_height)\n",
        "      row_index = min(row_index, num_rows - 1)  # Asegúrate de que el índice de fila no supere num_rows - 1\n",
        "      rows[row_index].append(box)\n",
        "\n",
        "\n",
        "    # Ordenar cuadros dentro de cada fila basándose en la posición horizontal\n",
        "    sorted_rows = [sorted(row, key=lambda box: box[0]) for row in rows]\n",
        "\n",
        "    # Aplanar las filas ordenadas en una sola lista de cuadros\n",
        "    sorted_boxes = [box for row in sorted_rows for box in row]\n",
        "\n",
        "    return sorted_boxes\n",
        "\n",
        "# Aplicar la ordenación dinámica por filas\n",
        "num_rows = 4\n",
        "sorted_boxes_by_rows_dynamic = sort_by_rows_dynamic(largest_bounding_boxes, num_rows)\n",
        "\n",
        "# El resto del código para recortar y guardar las imágenes sigue igual\n",
        "grid_cropped_signs = [original_img[y:y+h, x:x+w] for x, y, w, h in sorted_boxes_by_rows_dynamic]\n",
        "\n",
        "# Guardar las imágenes recortadas\n",
        "grid_file_paths = []\n",
        "for index, img in enumerate(grid_cropped_signs):\n",
        "    file_path = f\"/content/prueba1/5/sign_{chr(65 + index)}.jpg\"\n",
        "    cv2.imwrite(file_path, img)\n",
        "    grid_file_paths.append(file_path)\n",
        "\n",
        "grid_file_paths\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16t5QpR0vlsq",
        "outputId": "4d798e73-5713-40dc-e1d2-80c20845df41"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/prueba1/5/sign_A.jpg',\n",
              " '/content/prueba1/5/sign_B.jpg',\n",
              " '/content/prueba1/5/sign_C.jpg',\n",
              " '/content/prueba1/5/sign_D.jpg',\n",
              " '/content/prueba1/5/sign_E.jpg',\n",
              " '/content/prueba1/5/sign_F.jpg',\n",
              " '/content/prueba1/5/sign_G.jpg',\n",
              " '/content/prueba1/5/sign_H.jpg',\n",
              " '/content/prueba1/5/sign_I.jpg',\n",
              " '/content/prueba1/5/sign_J.jpg',\n",
              " '/content/prueba1/5/sign_K.jpg',\n",
              " '/content/prueba1/5/sign_L.jpg',\n",
              " '/content/prueba1/5/sign_M.jpg',\n",
              " '/content/prueba1/5/sign_N.jpg',\n",
              " '/content/prueba1/5/sign_O.jpg',\n",
              " '/content/prueba1/5/sign_P.jpg',\n",
              " '/content/prueba1/5/sign_Q.jpg',\n",
              " '/content/prueba1/5/sign_R.jpg',\n",
              " '/content/prueba1/5/sign_S.jpg',\n",
              " '/content/prueba1/5/sign_T.jpg',\n",
              " '/content/prueba1/5/sign_U.jpg',\n",
              " '/content/prueba1/5/sign_V.jpg',\n",
              " '/content/prueba1/5/sign_W.jpg',\n",
              " '/content/prueba1/5/sign_X.jpg',\n",
              " '/content/prueba1/5/sign_Y.jpg',\n",
              " '/content/prueba1/5/sign_Z.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}